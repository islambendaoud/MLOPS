{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c073a8be",
   "metadata": {},
   "source": [
    "# TP1 MLOPS : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee4b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8e35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef844e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>film-url</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-135259/c...</td>\n",
       "      <td>Si vous cherchez du cinéma abrutissant à tous ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-172430/c...</td>\n",
       "      <td>Trash, re-trash et re-re-trash...! Une horreur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-15105/cr...</td>\n",
       "      <td>Et si, dans les 5 premières minutes du film, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188629/c...</td>\n",
       "      <td>Mon dieu ! Quelle métaphore filée ! Je suis ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-23514/cr...</td>\n",
       "      <td>Premier film de la saga Kozure Okami, \"Le Sabr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>159995</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-132387/c...</td>\n",
       "      <td>Un rythme bien trop lent et un Ashton Kutcher ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>159996</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-53313/cr...</td>\n",
       "      <td>Monsieur Duchovny vous êtes aussi piètre acteu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>159997</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-248258/c...</td>\n",
       "      <td>Complètement différent des films de la série C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>159998</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-268731/c...</td>\n",
       "      <td>Alors franchement pour le moment c'est le meil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>159999</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188871/c...</td>\n",
       "      <td>Beur sur la ville réunit à lui même toutes les...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           film-url  \\\n",
       "0                0  http://www.allocine.fr/film/fichefilm-135259/c...   \n",
       "1                1  http://www.allocine.fr/film/fichefilm-172430/c...   \n",
       "2                2  http://www.allocine.fr/film/fichefilm-15105/cr...   \n",
       "3                3  http://www.allocine.fr/film/fichefilm-188629/c...   \n",
       "4                4  http://www.allocine.fr/film/fichefilm-23514/cr...   \n",
       "...            ...                                                ...   \n",
       "159995      159995  http://www.allocine.fr/film/fichefilm-132387/c...   \n",
       "159996      159996  http://www.allocine.fr/film/fichefilm-53313/cr...   \n",
       "159997      159997  http://www.allocine.fr/film/fichefilm-248258/c...   \n",
       "159998      159998  http://www.allocine.fr/film/fichefilm-268731/c...   \n",
       "159999      159999  http://www.allocine.fr/film/fichefilm-188871/c...   \n",
       "\n",
       "                                                   review  polarity  \n",
       "0       Si vous cherchez du cinéma abrutissant à tous ...         0  \n",
       "1       Trash, re-trash et re-re-trash...! Une horreur...         0  \n",
       "2       Et si, dans les 5 premières minutes du film, l...         0  \n",
       "3       Mon dieu ! Quelle métaphore filée ! Je suis ab...         0  \n",
       "4       Premier film de la saga Kozure Okami, \"Le Sabr...         1  \n",
       "...                                                   ...       ...  \n",
       "159995  Un rythme bien trop lent et un Ashton Kutcher ...         0  \n",
       "159996  Monsieur Duchovny vous êtes aussi piètre acteu...         0  \n",
       "159997  Complètement différent des films de la série C...         1  \n",
       "159998  Alors franchement pour le moment c'est le meil...         1  \n",
       "159999  Beur sur la ville réunit à lui même toutes les...         0  \n",
       "\n",
       "[160000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5937739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "film-url      0\n",
       "review        0\n",
       "polarity      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfb60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the table names Unnamed: 0\n",
    "df = df.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615a841c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film-url</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-135259/c...</td>\n",
       "      <td>Si vous cherchez du cinéma abrutissant à tous ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-172430/c...</td>\n",
       "      <td>Trash, re-trash et re-re-trash...! Une horreur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-15105/cr...</td>\n",
       "      <td>Et si, dans les 5 premières minutes du film, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188629/c...</td>\n",
       "      <td>Mon dieu ! Quelle métaphore filée ! Je suis ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-23514/cr...</td>\n",
       "      <td>Premier film de la saga Kozure Okami, \"Le Sabr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            film-url  \\\n",
       "0  http://www.allocine.fr/film/fichefilm-135259/c...   \n",
       "1  http://www.allocine.fr/film/fichefilm-172430/c...   \n",
       "2  http://www.allocine.fr/film/fichefilm-15105/cr...   \n",
       "3  http://www.allocine.fr/film/fichefilm-188629/c...   \n",
       "4  http://www.allocine.fr/film/fichefilm-23514/cr...   \n",
       "\n",
       "                                              review  polarity  \n",
       "0  Si vous cherchez du cinéma abrutissant à tous ...         0  \n",
       "1  Trash, re-trash et re-re-trash...! Une horreur...         0  \n",
       "2  Et si, dans les 5 premières minutes du film, l...         0  \n",
       "3  Mon dieu ! Quelle métaphore filée ! Je suis ab...         0  \n",
       "4  Premier film de la saga Kozure Okami, \"Le Sabr...         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0175bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a05e1",
   "metadata": {},
   "source": [
    "# Preprocessing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6697b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use sklearn feature extraction , preprocess the data \n",
    "# use the tf idf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as stopwords\n",
    "stopwords = list(stopwords)\n",
    "\n",
    "# apply it in the df  \n",
    "tfidf = TfidfVectorizer(stop_words = stopwords) \n",
    "\n",
    "X = tfidf.fit_transform(df[\"review\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d6d3a",
   "metadata": {},
   "source": [
    "# Conception : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9bc752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "y = df[\"polarity\"]\n",
    "\n",
    "\n",
    "model_log = LogisticRegression(max_iter = 2000)\n",
    "model_log.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46483102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d520006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 152189)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the tfidf vectorizer dumped before , and use it to transform the test data into tfidf matrix that has the same shape as the train data\n",
    "X_test = tfidf.transform(df_test[\"review\"])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc4e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test[\"polarity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83b7d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9223"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "562cf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precsion , recall , accuracy  of the model \n",
    "from sklearn.metrics import precision_score , recall_score , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585c9c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.9097675367047309\n",
      "recall :  0.9302543786488741\n",
      "accuracy :  0.9223\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_log.predict(X_test)\n",
    "\n",
    "print( \"precision : \",precision_score(y_test,y_pred)) \n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cef176",
   "metadata": {},
   "source": [
    "**precision is the ratio tp / (tp + fp) which means, the ration of the real positive between of those who were flagged as positive.**\n",
    "\n",
    "**recall is the ratio tp / (tp + fn) ratio of the real positives that we flagged as positive.**\n",
    "\n",
    "**accuracy is the fraction of predictions our model got right.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48199ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.9097675367047309\n",
      "recall :  0.9302543786488741\n",
      "accuracy :  0.9223\n"
     ]
    }
   ],
   "source": [
    "# create pipeline the gets the data , apply the tfidf of in \n",
    "# the data , and then apply the logistic regression model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([ (\"tfidf\",TfidfVectorizer(stop_words = stopwords)),(\"log\",LogisticRegression(max_iter = 2000))])\n",
    "\n",
    "pipe.fit(df[\"review\"],df[\"polarity\"])\n",
    "\n",
    "y_pred = pipe.predict(df_test[\"review\"])\n",
    "\n",
    "print( \"precision : \",precision_score(y_test,y_pred))\n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f7992eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.9110294867870625\n",
      "recall :  0.9308798999165971\n",
      "accuracy :  0.92325\n"
     ]
    }
   ],
   "source": [
    "# do the same with different C and penalty values of logistic regression\n",
    "# C = 2 , penalty = l2\n",
    "model_log2 = LogisticRegression(max_iter = 2000,C = 2, penalty = \"l2\")\n",
    "model_log2.fit(X,y)\n",
    "y_pred = model_log2.predict(X_test)\n",
    "print( \"precision : \",precision_score(y_test,y_pred))\n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e81236",
   "metadata": {},
   "source": [
    "**A little augmentation of the scores, we can see some augmentation in all of them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70243bae",
   "metadata": {},
   "source": [
    "# same using svc\n",
    "from sklearn.svm import SVC\n",
    "model_svc = SVC()\n",
    "model_svc.fit(X,y)\n",
    "y_pred = model_svc.predict(X_test)\n",
    "print( \"precision : \",precision_score(y_test,y_pred))\n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015eff70",
   "metadata": {},
   "source": [
    "# same using mlp classifier , use many architectures and hyperparameters \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model_mlp = MLPClassifier()\n",
    "model_mlp.fit(X,y)\n",
    "y_pred = model_mlp.predict(X_test)\n",
    "print( \"precision : \",precision_score(y_test,y_pred))\n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2db2ef",
   "metadata": {},
   "source": [
    "# use different architechture and hyperparameters\n",
    "model_mlp2 = MLPClassifier(hidden_layer_sizes = (100,100,100),max_iter = 1000)\n",
    "model_mlp2.fit(X,y)\n",
    "y_pred = model_mlp2.predict(X_test)\n",
    "print( \"precision : \",precision_score(y_test,y_pred))\n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eaa7f5",
   "metadata": {},
   "source": [
    "# another architecture\n",
    "model_mlp3 = MLPClassifier(hidden_layer_sizes = (100,100,100,100),max_iter = 1000)\n",
    "model_mlp3.fit(X,y)\n",
    "y_pred = model_mlp3.predict(X_test)\n",
    "print( \"precision : \",precision_score(y_test,y_pred))\n",
    "print( \"recall : \",recall_score(y_test,y_pred))\n",
    "print( \"accuracy : \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37501dba",
   "metadata": {},
   "source": [
    "# Optimization : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36516abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"../data/valid.csv\")\n",
    "X_valid = tfidf.transform(df_valid[\"review\"])\n",
    "y_valid = df_valid[\"polarity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:19<00:47,  3.41s/trial, best loss: 0.08040000000000003]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:32<00:32,  3.22s/trial, best loss: 0.08040000000000003]"
     ]
    }
   ],
   "source": [
    "#import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# use hyperopt to find the best hyperparameters for logistic regression\n",
    "\n",
    "# space of hyperparameters\n",
    "# use solver : 'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga' in the hyperopt space by using hp.pchoice\n",
    "space = {\n",
    "    'C': hp.uniform('C', 0.1, 10),\n",
    "    'penalty': hp.choice('penalty', ['l2']),\n",
    "    'solver': hp.pchoice('solver',[(1/6,'lbfgs'),(1/6,'liblinear'),(1/6,'newton-cg'),(1/6,'newton-cholesky'),(1/6, 'sag'),(1/6, 'saga')] ) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define the objective function\n",
    "def objective(params):\n",
    "    params = {'C': params['C'], 'penalty': params['penalty'] , 'solver' : params['solver']}\n",
    "    model = LogisticRegression(**params,max_iter = 100 )\n",
    "    model.fit(X , y )\n",
    "    y_pred = model.predict(X_valid)\n",
    "    score = accuracy_score(y_valid,y_pred)\n",
    "    loss = 1 - score\n",
    "    return loss\n",
    "\n",
    "# start the trials to find the best hyperparameters\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
